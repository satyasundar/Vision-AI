An example train-cmd run:

```
  >>>>python main.py train --SEED 2 --batch_size 64  --epochs 40 --lr 0.01  --dropout 0.05 --l1_weight 0.00002  --l2_weight_decay 0.000125 --L1 True --L2 False --data data --best_model_path saved_models --prefix data
  The config used for this run are @ data\config_params.txt
  Files already downloaded and verified
  (1600000, 32, 3)
  [0.49139968 0.48215841 0.44653091] [0.24703223 0.24348513 0.26158784]
  Files already downloaded and verified
  Files already downloaded and verified
  CUDA Available? True
  [Stats from Train Data]
   - Numpy Shape: (50000, 32, 32, 3)
   - Tensor Shape: torch.Size([50000, 32, 32, 3])
   - min: tensor(0, dtype=torch.uint8)
   - max: tensor(255, dtype=torch.uint8)
  [Stats from Test Data]
   - Numpy Shape: (10000, 32, 32, 3)
   - Tensor Shape: torch.Size([10000, 32, 32, 3])
   - min: tensor(0, dtype=torch.uint8)
   - max: tensor(255, dtype=torch.uint8)
  torch.Size([64, 3, 32, 32])
  torch.Size([64])
  Saving plot for a sample to ascertain RF required for edges & gradient D:\PG-ML\eva4\week7\consolidated\data\data_stats.png
  Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
  Saving plot 10 class samples to D:\PG-ML\eva4\week7\consolidated\data\plot_class_samples.png
  cuda
  ----------------------------------------------------------------
          Layer (type)               Output Shape         Param #
  ================================================================
              Conv2d-1            [-1, 3, 32, 32]              27
              Conv2d-2           [-1, 64, 32, 32]             192
     SeparableConv2d-3           [-1, 64, 32, 32]               0
         BatchNorm2d-4           [-1, 64, 32, 32]             128
             Dropout-5           [-1, 64, 32, 32]               0
                ReLU-6           [-1, 64, 32, 32]               0
              Conv2d-7           [-1, 64, 32, 32]             576
              Conv2d-8          [-1, 128, 32, 32]           8,192
     SeparableConv2d-9          [-1, 128, 32, 32]               0
        BatchNorm2d-10          [-1, 128, 32, 32]             256
            Dropout-11          [-1, 128, 32, 32]               0
               ReLU-12          [-1, 128, 32, 32]               0
          MaxPool2d-13          [-1, 128, 16, 16]               0
             Conv2d-14           [-1, 64, 16, 16]           8,192
        BatchNorm2d-15           [-1, 64, 16, 16]             128
            Dropout-16           [-1, 64, 16, 16]               0
               ReLU-17           [-1, 64, 16, 16]               0
             Conv2d-18           [-1, 64, 16, 16]             576
             Conv2d-19          [-1, 128, 16, 16]           8,192
    SeparableConv2d-20          [-1, 128, 16, 16]               0
        BatchNorm2d-21          [-1, 128, 16, 16]             256
            Dropout-22          [-1, 128, 16, 16]               0
               ReLU-23          [-1, 128, 16, 16]               0
          MaxPool2d-24            [-1, 128, 8, 8]               0
             Conv2d-25             [-1, 64, 8, 8]           8,192
        BatchNorm2d-26             [-1, 64, 8, 8]             128
            Dropout-27             [-1, 64, 8, 8]               0
               ReLU-28             [-1, 64, 8, 8]               0
             Conv2d-29             [-1, 64, 8, 8]             576
             Conv2d-30            [-1, 128, 8, 8]           8,192
    SeparableConv2d-31            [-1, 128, 8, 8]               0
        BatchNorm2d-32            [-1, 128, 8, 8]             256
            Dropout-33            [-1, 128, 8, 8]               0
               ReLU-34            [-1, 128, 8, 8]               0
          MaxPool2d-35            [-1, 128, 4, 4]               0
             Conv2d-36             [-1, 64, 4, 4]           8,192
        BatchNorm2d-37             [-1, 64, 4, 4]             128
            Dropout-38             [-1, 64, 4, 4]               0
               ReLU-39             [-1, 64, 4, 4]               0
             Conv2d-40             [-1, 64, 4, 4]             576
             Conv2d-41             [-1, 64, 4, 4]           4,096
    SeparableConv2d-42             [-1, 64, 4, 4]               0
        BatchNorm2d-43             [-1, 64, 4, 4]             128
            Dropout-44             [-1, 64, 4, 4]               0
               ReLU-45             [-1, 64, 4, 4]               0
          AvgPool2d-46             [-1, 64, 1, 1]               0
             Conv2d-47             [-1, 10, 1, 1]             640
  ================================================================
  Total params: 57,819
  Trainable params: 57,819
  Non-trainable params: 0
  ----------------------------------------------------------------
  Input size (MB): 0.01
  Forward/backward pass size (MB): 10.77
  Params size (MB): 0.22
  Estimated Total Size (MB): 11.01
  ----------------------------------------------------------------
  Model training starts on CIFAR10 dataset
  EPOCH: 1
  Loss=1.1553101539611816 Batch_id=781 Accuracy=45.42: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:39<00:00, 19.68it/s]

  Test set: Average loss: 1.3065, Accuracy: 5201/10000 (52.01%)

  validation-accuracy improved from 0 to 52.01, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-1_L1-1_L2-1_val_acc-52.01.h5
  EPOCH: 2
  Loss=1.2293564081192017 Batch_id=781 Accuracy=61.39: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:39<00:00, 19.70it/s]

  Test set: Average loss: 1.0566, Accuracy: 6233/10000 (62.33%)

  validation-accuracy improved from 52.01 to 62.33, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-2_L1-1_L2-1_val_acc-62.33.h5
  EPOCH: 3
  Loss=1.6857714653015137 Batch_id=781 Accuracy=66.33: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:40<00:00, 19.19it/s]

  Test set: Average loss: 1.0860, Accuracy: 6182/10000 (61.82%)

  EPOCH: 4
  Loss=1.2139606475830078 Batch_id=781 Accuracy=69.37: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 19.05it/s]

  Test set: Average loss: 1.0452, Accuracy: 6291/10000 (62.91%)

  validation-accuracy improved from 62.33 to 62.91, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-4_L1-1_L2-1_val_acc-62.91.h5
  EPOCH: 5
  Loss=0.5773859024047852 Batch_id=781 Accuracy=71.44: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:40<00:00, 19.09it/s]

  Test set: Average loss: 0.9164, Accuracy: 6775/10000 (67.75%)

  validation-accuracy improved from 62.91 to 67.75, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-5_L1-1_L2-1_val_acc-67.75.h5
  EPOCH: 6
  Loss=0.7604214549064636 Batch_id=781 Accuracy=73.40: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:40<00:00, 19.17it/s]

  Test set: Average loss: 0.7986, Accuracy: 7200/10000 (72.00%)

  validation-accuracy improved from 67.75 to 72.0, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-6_L1-1_L2-1_val_acc-72.0.h5
  EPOCH: 7
  Loss=0.6019574999809265 Batch_id=781 Accuracy=74.82: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:39<00:00, 19.59it/s]

  Test set: Average loss: 0.7584, Accuracy: 7390/10000 (73.90%)

  validation-accuracy improved from 72.0 to 73.9, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-7_L1-1_L2-1_val_acc-73.9.h5
  EPOCH: 8
  Loss=1.0551904439926147 Batch_id=781 Accuracy=76.11: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:42<00:00, 18.21it/s]

  Test set: Average loss: 0.8458, Accuracy: 7128/10000 (71.28%)

  EPOCH: 9
  Loss=1.0538208484649658 Batch_id=781 Accuracy=77.20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 18.71it/s]

  Test set: Average loss: 0.7529, Accuracy: 7403/10000 (74.03%)

  validation-accuracy improved from 73.9 to 74.03, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-9_L1-1_L2-1_val_acc-74.03.h5
  EPOCH: 10
  Loss=0.6241440176963806 Batch_id=781 Accuracy=77.97: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 19.00it/s]

  Test set: Average loss: 0.7825, Accuracy: 7286/10000 (72.86%)

  EPOCH: 11
  Loss=0.742887020111084 Batch_id=781 Accuracy=78.89: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 19.06it/s]

  Test set: Average loss: 0.7049, Accuracy: 7608/10000 (76.08%)

  validation-accuracy improved from 74.03 to 76.08, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-11_L1-1_L2-1_val_acc-76.08.h5
  EPOCH: 12
  Loss=1.1047850847244263 Batch_id=781 Accuracy=79.62: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 19.01it/s]

  Test set: Average loss: 0.6995, Accuracy: 7630/10000 (76.30%)

  validation-accuracy improved from 76.08 to 76.3, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-12_L1-1_L2-1_val_acc-76.3.h5
  EPOCH: 13
  Loss=0.24176143109798431 Batch_id=781 Accuracy=80.15: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:39<00:00, 19.59it/s]

  Test set: Average loss: 0.7038, Accuracy: 7589/10000 (75.89%)

  EPOCH: 14
  Loss=0.4260452389717102 Batch_id=781 Accuracy=80.62: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:40<00:00, 19.47it/s]

  Test set: Average loss: 0.6898, Accuracy: 7654/10000 (76.54%)

  validation-accuracy improved from 76.3 to 76.54, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-14_L1-1_L2-1_val_acc-76.54.h5
  EPOCH: 15
  Loss=0.5190249085426331 Batch_id=781 Accuracy=81.18: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:40<00:00, 19.49it/s]

  Test set: Average loss: 0.6392, Accuracy: 7816/10000 (78.16%)

  validation-accuracy improved from 76.54 to 78.16, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-15_L1-1_L2-1_val_acc-78.16.h5
  EPOCH: 16
  Loss=0.6705350875854492 Batch_id=781 Accuracy=81.59: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:40<00:00, 19.18it/s]

  Test set: Average loss: 0.6655, Accuracy: 7743/10000 (77.43%)

  EPOCH: 17
  Loss=0.6869875192642212 Batch_id=781 Accuracy=81.70: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 19.06it/s]

  Test set: Average loss: 0.6494, Accuracy: 7748/10000 (77.48%)

  EPOCH: 18
  Loss=0.39416778087615967 Batch_id=781 Accuracy=82.54: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 19.03it/s]

  Test set: Average loss: 0.6185, Accuracy: 7874/10000 (78.74%)

  validation-accuracy improved from 78.16 to 78.74, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-18_L1-1_L2-1_val_acc-78.74.h5
  EPOCH: 19
  Loss=0.49636441469192505 Batch_id=781 Accuracy=82.38: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 19.04it/s]

  Test set: Average loss: 0.6168, Accuracy: 7884/10000 (78.84%)

  validation-accuracy improved from 78.74 to 78.84, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-19_L1-1_L2-1_val_acc-78.84.h5
  EPOCH: 20
  Loss=0.4987145662307739 Batch_id=781 Accuracy=82.94: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 18.64it/s]

  Test set: Average loss: 0.6301, Accuracy: 7874/10000 (78.74%)

  EPOCH: 21
  Loss=0.27221041917800903 Batch_id=781 Accuracy=83.32: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 18.89it/s]

  Test set: Average loss: 0.6452, Accuracy: 7774/10000 (77.74%)

  EPOCH: 22
  Loss=0.4619467854499817 Batch_id=781 Accuracy=83.43: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 18.97it/s]

  Test set: Average loss: 0.6149, Accuracy: 7912/10000 (79.12%)

  validation-accuracy improved from 78.84 to 79.12, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-22_L1-1_L2-1_val_acc-79.12.h5
  EPOCH: 23
  Loss=0.628359317779541 Batch_id=781 Accuracy=83.36: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 18.81it/s]

  Test set: Average loss: 0.6105, Accuracy: 7921/10000 (79.21%)

  validation-accuracy improved from 79.12 to 79.21, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-23_L1-1_L2-1_val_acc-79.21.h5
  EPOCH: 24
  Loss=0.7213252186775208 Batch_id=781 Accuracy=83.95: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:46<00:00, 16.70it/s]

  Test set: Average loss: 0.6030, Accuracy: 7924/10000 (79.24%)

  validation-accuracy improved from 79.21 to 79.24, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-24_L1-1_L2-1_val_acc-79.24.h5
  EPOCH: 25
  Loss=0.8733128309249878 Batch_id=781 Accuracy=84.14: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:42<00:00, 18.27it/s]

  Test set: Average loss: 0.6122, Accuracy: 7934/10000 (79.34%)

  validation-accuracy improved from 79.24 to 79.34, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-25_L1-1_L2-1_val_acc-79.34.h5
  EPOCH: 26
  Loss=0.31511449813842773 Batch_id=781 Accuracy=84.56: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:43<00:00, 17.79it/s]

  Test set: Average loss: 0.6104, Accuracy: 7902/10000 (79.02%)

  EPOCH: 27
  Loss=0.8818047642707825 Batch_id=781 Accuracy=84.48: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 18.83it/s]

  Test set: Average loss: 0.5919, Accuracy: 8014/10000 (80.14%)

  validation-accuracy improved from 79.34 to 80.14, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-27_L1-1_L2-1_val_acc-80.14.h5
  EPOCH: 28
  Loss=0.2606501579284668 Batch_id=781 Accuracy=84.59: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 18.67it/s]

  Test set: Average loss: 0.6007, Accuracy: 7996/10000 (79.96%)

  EPOCH: 29
  Loss=0.40842732787132263 Batch_id=781 Accuracy=85.08: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 18.94it/s]

  Test set: Average loss: 0.5651, Accuracy: 8114/10000 (81.14%)

  validation-accuracy improved from 80.14 to 81.14, saving model to D:\PG-ML\eva4\week7\consolidated\saved_models\CIFAR10_model_epoch-29_L1-1_L2-1_val_acc-81.14.h5
  EPOCH: 30
  Loss=0.992738664150238 Batch_id=781 Accuracy=85.06: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:42<00:00, 18.52it/s]

  Test set: Average loss: 0.5755, Accuracy: 8035/10000 (80.35%)

  EPOCH: 31
  Loss=0.37750324606895447 Batch_id=781 Accuracy=85.16: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:40<00:00, 19.30it/s]

  Test set: Average loss: 0.5953, Accuracy: 8018/10000 (80.18%)

  EPOCH: 32
  Loss=0.7709054350852966 Batch_id=781 Accuracy=85.38: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 18.92it/s]

  Test set: Average loss: 0.5920, Accuracy: 8036/10000 (80.36%)

  EPOCH: 33
  Loss=0.6518959403038025 Batch_id=781 Accuracy=85.50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:40<00:00, 19.15it/s]

  Test set: Average loss: 0.5704, Accuracy: 8103/10000 (81.03%)

  EPOCH: 34
  Loss=0.8841572403907776 Batch_id=781 Accuracy=85.55: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 18.84it/s]

  Test set: Average loss: 0.5944, Accuracy: 7984/10000 (79.84%)

  EPOCH: 35
  Loss=0.5100325345993042 Batch_id=781 Accuracy=85.56: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 19.04it/s]

  Test set: Average loss: 0.6238, Accuracy: 7901/10000 (79.01%)

  EPOCH: 36
  Loss=0.5456987023353577 Batch_id=781 Accuracy=85.94: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:40<00:00, 19.15it/s]

  Test set: Average loss: 0.5844, Accuracy: 8065/10000 (80.65%)

  EPOCH: 37
  Loss=0.1929539144039154 Batch_id=781 Accuracy=86.06: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:40<00:00, 19.34it/s]

  Test set: Average loss: 0.6173, Accuracy: 7956/10000 (79.56%)

  EPOCH: 38
  Loss=0.5040670037269592 Batch_id=781 Accuracy=86.10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:40<00:00, 19.40it/s]

  Test set: Average loss: 0.5937, Accuracy: 8038/10000 (80.38%)

  EPOCH: 39
  Loss=0.22587764263153076 Batch_id=781 Accuracy=86.39: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 19.06it/s]

  Test set: Average loss: 0.5887, Accuracy: 8050/10000 (80.50%)

  EPOCH: 40
  Loss=0.47627636790275574 Batch_id=781 Accuracy=86.62: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [00:41<00:00, 18.84it/s]

  Test set: Average loss: 0.5936, Accuracy: 8012/10000 (80.12%)
```
