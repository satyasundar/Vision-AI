Group Members: Satya Nayak, Ramjee Ganti, Gourav Pattanaik, Jayant Ojha

#### Here is the description of 5 attempts, being made to achieve the required goals (meeting 99.4%+ accuracy, under the required parameters: <=10K and within 15 epochs) :

##### First Attempt:

Apart from setting up & stabilizing the infrastructure, for overall training and inference, the emphasis here is on fixing up the architecture and underlying elements, which can form the foundation on which to build upon.
Hence, an architecture as shown in the table below is chosen as a "baseline" one. Please refer the [notebook](https://github.com/ojhajayant/eva/blob/master/week5/S5_assignment_1st_attempt.ipynb) 

Input Channels/Image  |  Conv2d/Transform      | Output Channels | RF
---------------------|--------------|----------------------|----------------------
`28x28x1`              | `(3x3x1)x8`   |      `26x26x8`  |      `3x3`  **Input Block** [1 conv2d 3x3 layer]   
` `              | `ReLU`   |      ` `  |      ` ` 
`26x26x8`             | `(3x3x8)x8`  |      `24x24x8` |      `5x5`     **CONVOLUTION BLOCK 1** [1 conv2d 3x3 layer ] 
` `              | `ReLU`   |      ` `  |      ` ` 
**24x24x8**             |   **MP(2x2)**    |     **12x12x8**   |     **6x6**  **TRANSITION BLOCK 1**  [1 maxpool(2,2) & 1 conv2d 1x1 layers]                  
**12x12x8**             | **(1x1x8)x8**  |     **12x12x8**   |      **6x6** 
** **             | **ReLU**   |     ** **  |     ** **      
*12x12x8*             | *(3x3x8)x16*  |      *10x10x16* |      *10x10*  **CONVOLUTION BLOCK 2** [4 conv2d 3x3 layers]
** **             | *ReLU*   |     ** **  |    ** **                       
*10x10x16*             | *(3x3x16)x16*  |      *8x8x16* |      *14x14* 
** **             | *ReLU*   |     ** **  |    ** **    
*8x8x16*               | *(3x3x16)x16*  |      *6x6x16*  |      *18x18* 
** **             | *ReLU*   |     ** **  |    ** **   
*6x6x16*               | *(3x3x16)x20*  |      *6x6x20*  |      *22x22* (**Note 1:** o/p channels should be generated after *padding* here, hence you see *6x6* rather than 4x4.In terms of accuracy for 4x4 vs 6x6, it comes out to be better for 6x6, hence padding recommended here.   **Note 2:** also note that this 4x4 vs 6x6 has significance for the upcoming grad-cam assisted visualizations)
** **             | *ReLU*   |     ** **  |    ** **   
6x6x20               | GAP  LAYER (kernel_size=(6,6)   |      1x1x20          | `32x32` (22 + (6-1)x2 = 32) **OUTPUT BLOCK** [GAP + 1 conv2d 1x1 layer]
`1x1x20`               | `(1x1x20)x10`  |      `1x1x10`    |      `16x16`  (NO RELU at the o/p of this layer) 1 conv2d 1x1 layer
` `             | `log_SoftMax`   |     ` `  |     ` ` 

 above has 4 "components":
 
 1. **Input Block:** One initial, "Input Block" at the begining, to convolve over the "original image" 
    channel(s), due to the opposing constraints of meeting an accuracy number with lesser parameters possible,
    choosing  8 number of kernels for this 'separate' layer (which feeds in to the next "CONVOLUTION BLOCK 1",
    explained below).This 1 initial layer & one following layer (for "CONVOLUTION BLOCK 1") provide receptive
    field of 5x5 pixels(3->5) sufficient for the MNIST dataset's edges & gradient generation.    
	
 2. **CONVOLUTION BLOCK 1:** placed after the first "Input Block" layer, with 8 3x3 kernel conv2d assigned
    to this layer, so as to provide 8 o/p channels.
    
 3. **TRANSITION BLOCK 1:** max-pool(k=2,s=2) and a-1x1-feature-merger kernel, following the
    'CONVOLUTION BLOCK 1'.Provides 8 o/p channels.
    
 4. **CONVOLUTION BLOCK 2:** These are 4 layers of 3x3 conv2d operators, with 16, 16, 16, 20 o/p channels at
    each layer position respectively.Two points are note worthy: 
    **Note 1:** o/p channels should be generated after *padding* at the 4th layer o/p of this block, hence we
    find *6x6* rather than 4x4 as its o/p size. In terms of accuracy for 4x4 vs 6x6, it comes out to be better
    for 6x6, hence padding as 'same'/ or 1 recommended at 4th layer position of this CONVOLUTION BLOCK 2.
    **Note 2:** also note that this 4x4 vs 6x6 has significance for the upcoming grad-cam-assisted visualizations)
  
 5. **OUTPUT BLOCK:**: GAP layer followed by a 1x1 operator (which actually resembles a fully-connected(FC)
    layer in this case. A noteworthy point (which relates to the "capacity" element of the overall netowrk (NW))
    is that the FC (the 1x1 conv2d behaviour here) will work better, in generating the final 10 "class-features"
     to be used by the log_softmax.If the inputs to it, have more "features points", i.e. for example if we do 
     a 16->10 conversion, vs a 24->10conversion, we can expect the 10 class-features (for softmax to decide) 
     generated by a 24->10 conversion will be more "robust" (as compared to from 16->10 conversion)
     But here due to the parameter constraint, we try to use 20 o/ps at the end of the CONVOLUTION BLOCK 2.
     (i.e. a 20->10 conversion for the FC-like, 1x1 conv2d layer)

###### Targets:
	- expect the max Validation Accuracy to reach at least: ~99.0%
	- The total params in all these attempts has to be under 10K.
###### Results (1st Attempt):
	- max Validation Accuracy reached: ~98.97%
	- max Train Accuracy reached: ~99.08%
	- Total params: 9,552
  
![alt text](https://github.com/ojhajayant/eva/blob/master/week5/01_acc_loss.PNG "Logo Title Text 1")
##### Analysis:
	- There is lots of overfitting in terms of both the train and test accuracies running in 
	  close step.With not much "potential" for the test/validation accuracy to increase, with 
	  a corresponding increase in training accuracy. For example, in the final epoch while the 
	  train accuracy could reach 99.08%, but the validation accuracy is still at ~98.97.
	- But, we would now on, in next attempts like to see, how with added Batch-Norm, Dropout, the
	  NW-performance gets affected.

##### File Link:  [notebook](https://github.com/ojhajayant/eva/blob/master/week5/S5_assignment_1st_attempt.ipynb) 


##### Second Attempt:

While keeping all the other elements same as the "baseline" architecture from the 1st attempt, batchnorm layer is being
added under this 2nd attempt, which is expected to improve training, and increase the overall validation accuracy.We might
not see any improvement in the overfitting aspect though.Below table illustrates the organization.Please refer the [notebook](https://github.com/ojhajayant/eva/blob/master/week5/S5_assignment_2nd_attempt.ipynb)

Input Channels/Image  |  Conv2d/Transform      | Output Channels | RF
---------------------|--------------|----------------------|----------------------
`28x28x1`              | `(3x3x1)x8`   |      `26x26x8`  |      `3x3`  **Input Block** [1 conv2d 3x3 layer]    
` `              | `BN(8)`   |      ` `  |      ` `
` `              | `ReLU`   |      ` `  |      ` ` 
`26x26x8`             | `(3x3x8)x8`  |      `24x24x8` |      `5x5`     **CONVOLUTION BLOCK 1** [1 conv2d 3x3 layer ]
` `              | `BN(8)`   |      ` `  |      ` `
` `              | `ReLU`   |      ` `  |      ` ` 
**24x24x8**             |   **MP(2x2)**    |     **12x12x8**   |     **6x6** **TRANSITION BLOCK 1**  [1 maxpool(2,2) & 1 conv2d 1x1 layers]                      
**12x12x8**             | **(1x1x8)x8**  |     **12x12x8**   |      **6x6** 
** **             | **BN(8)**   |     ** **  |     ** **
** **             | **ReLU**   |     ** **  |     ** **      
*12x12x8*             | *(3x3x8)x16*  |      *10x10x16* |      *10x10*  **CONVOLUTION BLOCK 2** [4 conv2d 3x3 layers]
** **            | *BN(16)*   |     * *   |     * * 
** **             | *ReLU*   |     ** **  |    ** **                       
*10x10x16*             | *(3x3x16)x16*  |      *8x8x16* |      *14x14* 
** **            | *BN(16)*   |     * *   |     * * 
** **             | *ReLU*   |     ** **  |    ** **    
*8x8x16*               | *(3x3x16)x16*  |      *6x6x16*  |      *18x18* 
** **            | *BN(16)*   |     * *   |     * * 
** **             | *ReLU*   |     ** **  |    ** **   
*6x6x16*               | *(3x3x16)x20*  |      *6x6x20*  |      *22x22* (**Note 1:** o/p channels should be generated after *padding* here, hence you see *6x6* rather than 4x4.In terms of accuracy for 4x4 vs 6x6, it comes out to be better for 6x6, hence padding recommended here.   **Note 2:** also note that this 4x4 vs 6x6 has significance for the upcoming grad-cam assisted visualizations)
** **            | *BN(20)*   |     * *   |     * * 
** **             | *ReLU*   |     ** **  |    ** **   
6x6x20               | GAP  LAYER (kernel_size=(6,6)   |      1x1x20          | `32x32` (22 + (6-1)x2 = 32) **OUTPUT BLOCK** [GAP + 1 conv2d 1x1 layer]
`1x1x20`               | `(1x1x20)x10`  |      `1x1x10`    |      `16x16`  (NO RELU at the o/p of this layer) 
` `             | `log_SoftMax`   |     ` `  |     ` ` 

###### Targets:
	- expect the max Validation Accuracy to reach at least: ~99.3%
	- There will be slight increase in the total params as compared 
	  to 1st attempt. But the total params in all these attempts has
	  to be under 10K.
###### Results (2nd Attempt):
	- max Validation Accuracy reached: ~99.40%
	- max Train Accuracy reached: ~99.47%
	- Total params: 9,736
  
![alt text](https://github.com/ojhajayant/eva/blob/master/week5/02_acc_loss.PNG "Logo Title Text 1")
##### Analysis:
	- We see a lot better accuracy as we have touched 99.4 and in many peochs we are > 99.3%
	- But, we still have overfitting and we would hence like to use some regularization for our
	  3rd attempt (in form of using Dropout)

##### File Link:  [notebook](https://github.com/ojhajayant/eva/blob/master/week5/S5_assignment_2nd_attempt.ipynb) 


##### Third Attempt:

Still improving upon the 2nd attempt's architecture by adding Dropout, in this 3rd attempt we expect to 
overcome the overfitting issue and possibly increase or at least retain the validation accuracies from 2nd attempt.
We should be expecting increased validation accuracies w.r.t. to much lesser train accuracies now.Out of all the 
other tested % ranges for dropout, it was found for this NW that 10% dropout worked best.
The table below illustrates the organization for 3rd attempt.
Please refer the [notebook](https://github.com/ojhajayant/eva/blob/master/week5/S5_assignment_3rd_attempt.ipynb)

Input Channels/Image  |  Conv2d/Transform      | Output Channels | RF
---------------------|--------------|----------------------|----------------------
`28x28x1`              | `(3x3x1)x8`   |      `26x26x8`  |      `3x3`  **Input Block** [1 conv2d 3x3 layer]    
` `              | `BN(8)`   |      ` `  |      ` `
` `              | `Dropout(10%)`   |      ` `  |      ` `
` `              | `ReLU`   |      ` `  |      ` ` 
`26x26x8`             | `(3x3x8)x8`  |      `24x24x8` |      `5x5`     **CONVOLUTION BLOCK 1** [1 conv2d 3x3 layer ]
` `              | `BN(8)`   |      ` `  |      ` `
` `              | `Dropout(10%)`   |      ` `  |      ` `
` `              | `ReLU`   |      ` `  |      ` ` 
**24x24x8**             |   **MP(2x2)**    |     **12x12x8**   |     **6x6**  **TRANSITION BLOCK 1**  [1 maxpool(2,2) & 1 conv2d 1x1 layers]                     
**12x12x8**             | **(1x1x8)x8**  |     **12x12x8**   |      **6x6** 
** **             | **Dropout(10%)**   |     ** **  |     ** **
** **             | **BN(8)**   |     ** **  |     ** **
** **             | **ReLU**   |     ** **  |     ** **      
*12x12x8*             | *(3x3x8)x16*  |      *10x10x16* |      *10x10*  **CONVOLUTION BLOCK 2** [4 conv2d 3x3 layers]
** **            | *BN(16)*   |     * *   |     * * 
** **             | *Dropout(10%)*   |     * *   |     * * 
** **             | *ReLU*   |     ** **  |    ** **                       
*10x10x16*             | *(3x3x16)x16*  |      *8x8x16* |      *14x14* 
** **            | *BN(16)*   |     * *   10%|     * * 
** **             | *Dropout(10%)*   |     * *   |     * * 
** **             | *ReLU*   |     ** **  |    ** **    
*8x8x16*               | *(3x3x16)x16*  |      *6x6x16*  |      *18x18* 
** **            | *BN(16)*   |     * *   |     * * 
** **             | *Dropout(10%)*   |     * *   |     * * 
** **             | *ReLU*   |     ** **  |    ** **   
*6x6x16*               | *(3x3x16)x20*  |      *6x6x20*  |      *22x22* (**Note 1:** o/p channels should be generated after *padding* here, hence you see *6x6* rather than 4x4.In terms of accuracy for 4x4 vs 6x6, it comes out to be better for 6x6, hence padding recommended here.   **Note 2:** also note that this 4x4 vs 6x6 has significance for the upcoming grad-cam assisted visualizations)
** **            | *BN(20)*   |     * *   |     * * 
** **             | *Dropout(10%)*   |     * *   |     * * 
** **             | *ReLU*   |     ** **  |    ** **   
6x6x20               | GAP  LAYER (kernel_size=(6,6)   |      1x1x20          | `32x32` (22 + (6-1)x2 = 32)**OUTPUT BLOCK** [GAP + 1 conv2d 1x1 layer]
`1x1x20`               | `(1x1x20)x10`  |      `1x1x10`    |      `16x16`  (NO RELU at the o/p of this layer) 
` `             | `log_SoftMax`   |     ` `  |     ` ` 

###### Targets:
	- expect the max Validation Accuracy to reach at least: ~99.3%
	- There will be no increase in the total params as compared 
	  to 2nd attempt. Total params in all these attempts has
	  to be under 10K.
###### Results (3rd Attempt):
	- max Validation Accuracy reached: ~99.47%
	- max Train Accuracy reached: ~98.92%
	- Total params: 9,736
  
![alt text](https://github.com/ojhajayant/eva/blob/master/week5/03_acc_loss.PNG "Logo Title Text 1")
##### Analysis:
	- We see a lots of improvement in terms of overfitting for example in the max case itself
	  for a train accuracy of 98.82% we get a validation accuracy of ~99.47%.
	- We in our next set of attempts should try to look for appropriate learning rates to get more 
	  improvements.

##### File Link:  [notebook](https://github.com/ojhajayant/eva/blob/master/week5/S5_assignment_3rd_attempt.ipynb) 

##### Fourth Attempt:

Under this 4th attempt, have tried to sweep the learning rate ranges from 1.0 downwards in the gaps of 0.1 resolution to find an appropriate learning rate range. In one experiment the range 0.2 to 0.1 'flashed' a better accuracy number, hence the file shown 
in this attempt tries to go deeper in the 0.2 downwards range in each epoch (with step size 1, with gamma such that every epoch the 
reduction in learning rate would be 0.001/TOTAL_EPOCHS:
```
(i.e. 
with init_learning_rate = 0.2
gamma x init_learning_rate = (init_learning_rate - (0.001/TOTAL_EPOCHS)   while step_size = 1)
```

```python
init_learning_rate = 0.2
TOTAL_EPOCHS = 15
gamma= (init_learning_rate - (0.001/TOTAL_EPOCHS))/init_learning_rate
optimizer = optim.SGD(model.parameters(), lr=init_learning_rate, momentum=0.9)
scheduler = StepLR(optimizer, step_size=1, gamma=gamma)
 ```
from the logs for this atempt, for 13th epoch as below, we find that around LR = 0.19900 we get a higher validation accuracy value:
Hence in the 5th and final attempt we will get finer into this learning rate to see if we can reach into any 'crevice' of higher accuracy. 

```
EPOCH: 13
Loss=0.008239701390266418 Batch_id=937 Accuracy=98.83: 100%|█████████████████████████| 938/938 [00:15<00:00, 58.67it/s]
LR: [0.19900232996633097]
Test set: Average loss: 0.0215, Accuracy: 9936/10000 (99.36%)
```

Please refer the [notebook](https://github.com/ojhajayant/eva/blob/master/week5/S5_assignment_4th_attempt.ipynb)

###### Targets:
	- This is an observational attempt (with underlying many learning rate sweeps attempted in 
	  the backgrould to see the appropriate range to further do a finer selction)--- ~99.4%
	- There will be no increase in the total params as compared to previous attempts. Total 
	  params in all these attempts has to be under 10K.
	- main outcome of this attempt was to get an appropraite learning rate around which we
	  can do finer exploration in the final attempt
###### Results (4th Attempt):
	- max Validation Accuracy reached: ~99.36%
	- max Train Accuracy reached: ~98.84%
	- Total params: 9,736
  
![alt text](https://github.com/ojhajayant/eva/blob/master/week5/04_acc_loss.PNG "Logo Title Text 1")
##### Analysis:
	- We try to see a suitable learning rate here.
	- We in our next set of attempts should try to look for appropriate learning rates to get more 
	  improvements.
	- Separately tried to include the image augmentation (rotation), but the results weren't good
	  hence not including it.

##### File Link:  [notebook](https://github.com/ojhajayant/eva/blob/master/week5/S5_assignment_4th_attempt.ipynb) 


##### Fifth Attempt:

Under this 5th attempt, have tried to sweep the learning rate ranges in mucch finer way around the learning rate found in the 
4th attempt i.e. 0.199. Here the gamma is being set so that in every epoch we reduce by (0.0001/TOTAL_EPOCHS) 
i.e. LR taken thru : [0.199, 0.19898666689000563, 0.19898000067000934 ...etc]
```
(i.e. 
with init_learning_rate = 0.199
gamma x init_learning_rate = (init_learning_rate - (0.0001/TOTAL_EPOCHS)   while step_size = 1)
```

```python
init_learning_rate = 0.199
TOTAL_EPOCHS = 15
gamma= (init_learning_rate - (0.0001/TOTAL_EPOCHS))/init_learning_rate
optimizer = optim.SGD(model.parameters(), lr=init_learning_rate, momentum=0.9)
scheduler = StepLR(optimizer, step_size=1, gamma=gamma)
 ```

Please refer the [notebook](https://github.com/ojhajayant/eva/blob/master/week5/S5_assignment_5th_attempt.ipynb)

###### Targets:
	- > 99.4+ & also a consistently higher accuracies.
	- There will be no increase in the total params as compared to previous attempts. Total 
	  params in all these attempts has to be under 10K.

###### Results (5th Attempt):
	- max Validation Accuracy reached: ~99.44%
	- max Train Accuracy reached: ~98.86%
	- Total params: 9,736
  
![alt text](https://github.com/ojhajayant/eva/blob/master/week5/05_acc_loss.PNG "Logo Title Text 1")
##### Analysis:
	- We observe a more consistent 99.3+% performance, with validation accuracy finally reaching 99.44%
	- The rotation image augmentation in a separate investigation didn't help in this case, hence didn't use it.


##### File Link:  [notebook](https://github.com/ojhajayant/eva/blob/master/week5/S5_assignment_5th_attempt.ipynb) 
